Part 4 — Ethical Reflection (5%)

Project: Example — Personal Recommendation System

Reflection (approx. 150-200 words):
In a past personal project building a content recommendation system, I would ensure ethical alignment by embedding fairness, transparency, and user autonomy from the start. First, I would perform a data inventory and document sources to identify potential biases (e.g., overrepresentation of particular user groups). I would choose evaluation metrics beyond accuracy — including exposure parity and disparate impact across demographic slices — and run periodic audits. To respect autonomy, the product would include clear consent flows for data collection and allow users to opt out or correct their data. Explainability measures (e.g., simple feature attributions or short reason templates) would accompany recommendations to inform users why a piece of content was suggested. For high-stakes scenarios (e.g., health or finance content), I would limit or flag algorithmic suggestions and require human curators to review outcomes. Finally, I would implement a monitoring pipeline to log outcomes, detect distributional shifts, and trigger retraining or human review when fairness metrics degrade. Governance steps include an internal checklist for privacy and fairness, stakeholder reviews, and external audits for transparency. By combining technical mitigation, clear user controls, and governance, the project can better align with ethical AI principles.