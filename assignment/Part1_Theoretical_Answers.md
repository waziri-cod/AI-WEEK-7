Part 1 — Theoretical Answers (30%)

Q1: Define algorithmic bias and provide two examples.
- Definition: Algorithmic bias occurs when an AI system produces systematically unfair outcomes for certain groups, typically because of skewed training data, inappropriate model design, or biased objectives. Bias can manifest as disparate treatment or disparate impact on protected groups.
- Example 1 (Hiring): A recruiting model trained on historical hiring data that favored men learns to downgrade resumes containing indicators associated with female applicants.
- Example 2 (Recidivism Risk): A risk-assessment model that uses arrest records and other correlated variables assigns higher risk scores to minority groups due to structural biases in policing.

Q2: Explain the difference between transparency and explainability in AI. Why are both important?
- Transparency: Refers to openness about how a system is built and what data, objectives, and processes it uses (e.g., data sources, model architecture, training procedures).
- Explainability: Refers to the ability to provide understandable, human-centered explanations for specific model decisions or behaviors (e.g., feature attributions, counterfactuals).
- Importance: Transparency enables auditing, accountability, and regulatory compliance; explainability helps users, stakeholders, and impacted individuals understand and contest decisions. Together they increase trust and enable remediation of harms.

Q3: How does GDPR impact AI development in the EU?
- Data protection and lawful processing: AI systems must have lawful bases for processing personal data and minimize data collected.
- Data subject rights: Individuals have rights (access, rectification, erasure, portability, objection) that AI systems must respect.
- Automated decision-making: GDPR includes protections against solely automated decisions producing legal or similarly significant effects; it requires safeguards including human review and explanations where applicable.
- Accountability and DPIA: Organizations must demonstrate compliance (records, Data Protection Impact Assessments) especially for high-risk processing.

Ethical Principles Matching
- A) Justice: Fair distribution of AI benefits and risks.
- B) Non-maleficence: Ensuring AI does not harm individuals or society.
- C) Autonomy: Respecting users’ right to control their data and decisions.
- D) Sustainability: Designing AI to be environmentally friendly.
