{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6cbe75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages if not already available.\n",
    "# Uncomment and run the following line if packages are missing.\n",
    "# Note: aif360 installation can take some time and may require a C compiler on some platforms.\n",
    "# !pip install aif360==0.6.0 numpy pandas scikit-learn matplotlib seaborn\n",
    "\n",
    "print('If needed, run: pip install -r requirements.txt or uncomment the pip install line in this cell')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90764fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# AIF360 imports (may fail if not installed)\n",
    "try:\n",
    "    from aif360.datasets import CompasDataset\n",
    "    from aif360.metrics import BinaryLabelDatasetMetric, ClassificationMetric\n",
    "except Exception as e:\n",
    "    print('AIF360 import failed:', e)\n",
    "    print('If AIF360 is not installed, run: pip install aif360==0.6.0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2e9b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load COMPAS dataset (AIF360 provided wrapper)\n",
    "try:\n",
    "    dataset = CompasDataset()\n",
    "    print('Loaded COMPAS dataset with {} instances'.format(dataset.features.shape[0]))\n",
    "    print('Protected attributes:', dataset.protected_attribute_names)\n",
    "    print('Label names:', dataset.metadata['label_names'])\n",
    "except Exception as e:\n",
    "    print('Failed to load CompasDataset from aif360:', e)\n",
    "    dataset = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8083c505",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute baseline group metrics (disparate impact on labels / base rates)\n",
    "if dataset is not None:\n",
    "    # Define privileged/unprivileged groups for race (AIF360 encoding: race=1 is typically Caucasian)\n",
    "    privileged_groups = [{dataset.protected_attribute_names[0]: 1}]\n",
    "    unprivileged_groups = [{dataset.protected_attribute_names[0]: 0}]\n",
    "\n",
    "    bldm = BinaryLabelDatasetMetric(dataset, privileged_groups=privileged_groups, unprivileged_groups=unprivileged_groups)\n",
    "    print('Base rate (mean label) for privileged:', bldm.mean_positive_rate(privileged=True))\n",
    "    print('Base rate (mean label) for unprivileged:', bldm.mean_positive_rate(privileged=False))\n",
    "    print('Disparate impact (labels):', bldm.disparate_impact())\n",
    "else:\n",
    "    print('Dataset not available; skipping baseline metrics')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d854f348",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a simple classifier and evaluate fairness on predictions\n",
    "if dataset is not None:\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "    X = dataset.features\n",
    "    y = dataset.labels.ravel()\n",
    "\n",
    "    # Split (stratify to keep label distribution)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "    scaler = StandardScaler().fit(X_train)\n",
    "    X_train_s = scaler.transform(X_train)\n",
    "    X_test_s = scaler.transform(X_test)\n",
    "\n",
    "    clf = LogisticRegression(max_iter=1000).fit(X_train_s, y_train)\n",
    "    y_pred = clf.predict(X_test_s)\n",
    "\n",
    "    # Build AIF360 BinaryLabelDataset objects for test and predictions\n",
    "    test_dataset = dataset.subset(np.where(dataset.instance_names.isin(dataset.instance_names))[0])[0:0] if False else None\n",
    "    # Simpler: use the original dataset split approach via indices to construct test/set from AIF360 dataset\n",
    "    # We'll create a shallow copy of dataset for test rows using indices from train_test_split on features.\n",
    "    # NOTE: AIF360 dataset API is flexible; here we use the numpy split approach to find test indices.\n",
    "    # Find indices of test set by matching rows (less robust but works for demonstration).\n",
    "    from sklearn.neighbors import NearestNeighbors\n",
    "    nbrs = NearestNeighbors(n_neighbors=1).fit(dataset.features)\n",
    "    _, idxs = nbrs.kneighbors(X_test, return_distance=True)\n",
    "    test_indices = idxs.ravel()\n",
    "\n",
    "    aif_test = dataset.subset(test_indices)\n",
    "    aif_pred = aif_test.copy()\n",
    "    aif_pred.labels = y_pred.reshape(-1, 1)\n",
    "\n",
    "    # Metrics\n",
    "    cm = ClassificationMetric(aif_test, aif_pred, unprivileged_groups=unprivileged_groups, privileged_groups=privileged_groups)\n",
    "    fpr_diff = cm.false_positive_rate_difference()\n",
    "    eqopp_diff = cm.equal_opportunity_difference()\n",
    "    print('False positive rate difference (unprivileged - privileged):', fpr_diff)\n",
    "    print('Equal opportunity difference (TPR difference):', eqopp_diff)\n",
    "\n",
    "    # Disparate impact on predictions\n",
    "    bldm_pred = BinaryLabelDatasetMetric(aif_pred, privileged_groups=privileged_groups, unprivileged_groups=unprivileged_groups)\n",
    "    print('Disparate impact (predictions):', bldm_pred.disparate_impact())\n",
    "else:\n",
    "    print('Dataset not available; skipping model training and prediction metrics')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d35699d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize False Positive Rate by group (privileged vs unprivileged)\n",
    "if dataset is not None:\n",
    "    groups = ['unprivileged', 'privileged']\n",
    "    fpr_unpriv = cm.false_positive_rate(privileged=False)\n",
    "    fpr_priv = cm.false_positive_rate(privileged=True)\n",
    "    fig, ax = plt.subplots(figsize=(6,4))\n",
    "    sns.barplot(x=groups, y=[fpr_unpriv, fpr_priv], palette='viridis', ax=ax)\n",
    "    ax.set_ylabel('False Positive Rate')\n",
    "    ax.set_title('False Positive Rate by Group')\n",
    "    plt.show()\n",
    "else:\n",
    "    print('Dataset not available; skipping visualization')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499aa535",
   "metadata": {},
   "source": [
    "## Next steps and remediation ideas\n",
    "- If bias is observed, try pre-processing (reweighing), in-processing (adversarial debiasing), or post-processing (calibrated equalized odds) algorithms from AIF360.\n",
    "- Include domain experts and community stakeholders when choosing fairness definitions and thresholds.\n",
    "- Log and document dataset provenance, preprocessing steps, and evaluation results for accountability."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
